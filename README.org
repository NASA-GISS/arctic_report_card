
#+PROPERTY: header-args:jupyter-python+ :session ARC2023 :dir ~/projects/arctic_report_card

* Table of contents                               :toc_4:noexport:
- [[#introduction][Introduction]]
- [[#mass-loss-from-citetmankoff_2021][Mass loss from citet:mankoff_2021]]
  - [[#baseline-mass-loss-calendar-years][Baseline mass loss (calendar years)]]
  - [[#1991----2020-hydro-years][1991 -- 2020 hydro years]]
  - [[#2023-mass-loss][2023 mass loss]]
  - [[#match-grace-reporting-period][Match GRACE reporting period]]
- [[#discharge][Discharge]]
  - [[#baseline-discharge-1991-through-2020][Baseline discharge (1991 through 2020)]]
  - [[#average-since-2013][Average since 2013]]
  - [[#2023-discharge-through-latest-update][2023 discharge through latest update]]
  - [[#trends][Trends]]
    - [[#all-gis][All GIS]]
    - [[#by-region][By region]]
    - [[#publication-graphic][Publication graphic]]
- [[#greenland-outline][Greenland outline]]
- [[#bare-ice-area][Bare ice area]]
- [[#melt][Melt]]
  - [[#figure][Figure]]
- [[#promice-in-situ--point-obs][PROMICE In situ / Point obs]]

* Introduction

GISS contributions to the Arctic Report Card

* Mass loss from citet:mankoff_2021

#+BEGIN_SRC bash :exports both :results verbatim
# July 23 2023 v 609
# https://dataverse.geus.dk/file.xhtml?persistentId=doi:10.22008/FK2/OHI23Z/CU1ITY&version=655
wget https://dataverse.geus.dk/api/access/datafile/51358 -O MB_region.nc
#+END_SRC

#+RESULTS:

** Baseline mass loss (calendar years)

+ ~ 218 Gt yr-1

#+NAME: baseline_mass_loss
#+BEGIN_SRC jupyter-python :exports both :results verbatim
%cd '/home/kdm/projects/arctic_report_card'

import xarray as xr
ds = xr.open_dataset("MB_region.nc")

print(ds\
      .sum(dim='region')\
      .sel({'time':slice('2002-01-01','2022-12-31')})\
      .mean()*365)
#+END_SRC

#+RESULTS: baseline_mass_loss
#+begin_example
/home/kdm/projects/arctic_report_card
<xarray.Dataset>
Dimensions:      ()
Data variables: (12/19)
    MB           float64 -217.8
    MB_err       float64 91.88
    MB_ROI       float64 -217.8
    MB_ROI_err   float64 157.1
    SMB          float64 291.5
    SMB_err      float64 26.23
    ...           ...
    BMB_err      float64 5.586
    BMB_ROI      float64 23.95
    BMB_ROI_err  float64 5.497
    MB_HIRHAM    float64 -221.9
    MB_MAR       float64 -209.6
    MB_RACMO     float64 -218.5
#+end_example

** 1991 -- 2020 hydro years

#+BEGIN_SRC jupyter-python :exports both :display plain
ds.sum(dim='region')\
  .sel({'time':slice('1990-09-01','2020-08-31')})\
  .resample({'time':'AS-SEP'})\
  .sum()\
  .mean()\
  [['MB','MB_err','SMB','SMB_err','BMB','BMB_err','D','D_err']]
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:  ()
Data variables:
    MB       float32 -162.8
    MB_err   float32 88.33
    SMB      float32 325.3
    SMB_err  float32 29.28
    BMB      float32 23.06
    BMB_err  float32 5.501
    D        float32 465.1
    D_err    float32 43.26
#+end_example

** 2023 mass loss

#+BEGIN_SRC jupyter-python :exports both :display plain
ds.sum(dim='region')\
  .sel({'time':slice('2022-09-01','2023-08-31')})\
  .sum()\
  [[_ for _ in ds.data_vars if 'err' not in _]]
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:    ()
Data variables:
    MB         float32 -201.5
    MB_ROI     float32 -201.6
    SMB        float32 317.1
    SMB_ROI    float32 317.1
    D          float32 491.5
    D_ROI      float32 491.6
    BMB        float32 27.2
    BMB_ROI    float32 27.2
    MB_HIRHAM  float32 -124.1
    MB_MAR     float32 -279.1
    MB_RACMO   float32 0.0
#+end_example

** Match GRACE reporting period

#+BEGIN_SRC jupyter-python :exports both :display plain
ds.sum(dim='region')\
  .sel({'time':slice('2022-07-01','2023-06-30')})\
  .sum(dim='time')\
  [[_ for _ in ds.data_vars if 'err' not in _]]
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:    ()
Data variables:
    MB         float32 -85.12
    MB_ROI     float32 -85.12
    SMB        float32 435.3
    SMB_ROI    float32 435.3
    D          float32 496.8
    D_ROI      float32 496.8
    BMB        float32 23.65
    BMB_ROI    float32 23.65
    MB_HIRHAM  float32 -35.77
    MB_MAR     float32 -134.5
    MB_RACMO   float32 0.0
#+end_example

SMB from GRACE
+ [ ] -279 + 496 + 23 = 240 # hydro year, see above.
+ [ ] -134 + 496 + 23 = 385 # GRACE period
+ [ ] -35 + 496 + 23  = 484 # RACMO rather than MAR

+ [ ] GRACE MB (from Google Doc) = -90
+ [ ] MB = SMB - D - BMB => SMB = MB + D + BMB => -90*0.84 + 496 + 23 = 443.4
  + Scale by 0.84 to remove peripheral ice

* Discharge

+ Using v87 from https://dataverse.geus.dk/dataset.xhtml?persistentId=doi:10.22008/promice/data/ice_discharge/d/v02

** Baseline discharge (1991 through 2020)

#+BEGIN_SRC jupyter-python :exports both
import xarray as xr
ds = xr.open_dataset("~/data/Mankoff_2020/ice/v87/region.nc").sum(dim='region')

df = ds[['discharge','err']].to_dataframe()['1990':]
df['1991-01-01':'2020-12-31':].mean()
df['1991-01-01':'2020-12-31':].resample('1D').interpolate().sum()/30/365
df['1991-01-01':'2020-12-31':].resample('1D').interpolate().mean()
#+END_SRC

#+RESULTS:
: discharge    465.427347
: err           43.289267
: dtype: float64



** Average since 2013

#+BEGIN_SRC jupyter-python :exports both
df['2013-01-01':].resample('1D').interpolate().mean()
#+END_SRC

#+RESULTS:
: discharge    497.493204
: err           47.151385
: dtype: float64

** 2023 discharge through latest update

#+BEGIN_SRC jupyter-python :exports both
print("Last timestamp: ", df.index[-1])
df['2023-01-01':'2023-12-31'].resample('1D').interpolate().mean()
#+END_SRC

#+RESULTS:
:RESULTS:
: Last timestamp:  2023-08-19 00:00:00
: discharge    489.208185
: err           46.120049
: dtype: float64
:END:


** Trends

See [[./figs_tmp]] sub-folder for graphics

*** All GIS

#+BEGIN_SRC jupyter-python :exports both
df['discharge'].resample('1D').interpolate().resample('YS').mean().plot(drawstyle='steps-post')
df['discharge'].resample('1D').interpolate().resample('YS').mean().tail()
#+END_SRC

#+RESULTS:
:RESULTS:
: time
: 2019-01-01    498.118339
: 2020-01-01    508.335361
: 2021-01-01    513.217558
: 2022-01-01    506.591594
: 2023-01-01    489.263787
: Freq: AS-JAN, Name: discharge, dtype: float64
[[file:./figs_tmp/774af5d75f6bbbcc942618ed999f85a51dc64351.png]]
:END:

*** By region

#+BEGIN_SRC jupyter-python :exports both
dsR = xr.open_dataset("~/data/Mankoff_2020/ice/v83/region.nc")

# dsR = dsR['discharge'].resample({'time':'1D'}).interpolate().resample({'time':'MS'}).mean()
dsR = dsR['discharge'].resample({'time':'1D'}).interpolate().resample({'time':'YS'}).mean()
_ = dsR.plot.line(x='time', drawstyle='steps-post')
#+END_SRC

#+RESULTS:
[[file:./figs_tmp/6742799f03de95bf9f5ff1e2cb55c7c1e55ede79.png]]


*** Publication graphic

#+BEGIN_SRC jupyter-python :results raw drawer :display text/plain :eval no-export
import matplotlib.gridspec as gridspec
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj
import matplotlib.pyplot as plt
import datetime as dt

from cycler import cycler
plt.rcParams['axes.prop_cycle'] = cycler('color', ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', \
                                                   '#9467bd', '#8c564b', '#e377c2', '#bcbd22', '#17becf'])

fig = plt.figure(1, figsize=(9,7)) # w,h
fig.clf()
grid = plt.GridSpec(2, 1, height_ratios=[1,6], hspace=0.1) # h, w

ax_D = fig.add_subplot(grid[1,:])

from adjust_spines import adjust_spines as adj
adj(ax_D, ['left','bottom'])

ROOT="./out/"
ROOT="/home/kdm/data/Mankoff_2020/ice/v87/"
D = pd.read_csv(ROOT+"region_D.csv", index_col=0, parse_dates=True)
err = pd.read_csv(ROOT+"region_err.csv", index_col=0, parse_dates=True)
coverage = pd.read_csv(ROOT+"region_coverage.csv", index_col=0, parse_dates=True)

THRESH = coverage < 0.5
D[THRESH] = np.nan
err[THRESH] = np.nan
coverage[THRESH] = np.nan

# PROMICE drop in SE. Need 200 m data
D = D.iloc[:-5]
err = err.iloc[:-5]
coverage = coverage.iloc[:-5]

def pad_df(df):
    df = pd.concat([pd.DataFrame(index=np.array(['1986-01-01']).astype('datetime64[ns]')), df] )
    idx = str(df.index.year.max())+'-12-31'
    df = pd.concat([df, pd.DataFrame(index=np.array([idx]).astype('datetime64[ns]'))])
    df = df.sort_index()
    return df

D = pad_df(D)
err = pad_df(err)
coverage = pad_df(coverage)

### Take annual average from daily interpolated rather than the existing samples.
D_day_year = D.resample('1D',axis='rows').mean().interpolate(method='time',limit_area='inside').resample('A',axis='rows').mean()
err_day_year=err.resample('1D',axis='rows').mean().interpolate(method='time',limit_area='inside').resample('A',axis='rows').mean()

# No annual average if few sample
num_obs = D.resample('Y').count().values
D_day_year[num_obs<=3] = np.nan
err_day_year[num_obs<=3] = np.nan

MS=4
Z=99
for r in D.columns:
    e = ax_D.errorbar(D[r].index, D[r].values, fmt='o', mfc='none', ms=MS)
    C = e.lines[0].get_color()
    D_day_year[r].plot(drawstyle='steps', linewidth=2, ax=ax_D,
                       color=C,
                       alpha=0.75, zorder=Z)
    for i in np.arange(D.index.size):
        if np.isnan(D.iloc[i][r]): continue
        alpha = coverage.iloc[i][r]
        if alpha < 0: alpha = 0
        if alpha > 1: alpha = 1
        ax_D.errorbar(D.iloc[i].name, D.iloc[i][r],
                      yerr=err.iloc[i][r], ecolor='gray',
                      marker='o', ms=MS,
                      # mfc='k', mec='k',
                      color=C,
                      mfc=C, mec=C,
                      alpha=alpha)

    tx = pd.Timestamp(str(D[r].dropna().index[-1].year) + '-01-01') + dt.timedelta(days=380)
    ty = D_day_year[r].dropna().iloc[-1]
    # if r in ['CE', 'SW']: ty=ty-4
    if r == 'CE': ty=ty-4
    # if r == 'NE': ty=ty+4
    # if r == 'NO': ty=ty-2
    ax_D.text(tx, ty, r, verticalalignment='center', horizontalalignment='left')

import matplotlib.dates as mdates
ax_D.xaxis.set_major_locator(mdates.YearLocator())

# plt.legend()
ax_D.legend("", framealpha=0)
ax_D.set_xlabel('Time [Years]')
ax_D.set_ylabel('Discharge [Gt yr$^{-1}$]')
ax_D.set_xlim(D.index[0], D.index[-1])
ax_D.set_xticklabels(D.index.year.unique())

ax_D.xaxis.set_tick_params(rotation=-90)
for tick in ax_D.xaxis.get_majorticklabels():
    tick.set_horizontalalignment("left")

plt.savefig('./discharge_ts_regions.png', transparent=False, bbox_inches='tight', dpi=300)
plt.savefig('./discharge_ts_regions.svg', transparent=False, bbox_inches='tight', dpi=300)

Err_pct = (err_day_year.values/D_day_year.values*100).round().astype(int).astype(str)
Err_pct[Err_pct.astype(float)<0] = 'NaN'
tbl = (D_day_year.round().fillna(value=0).astype(int).astype(str) + ' ('+Err_pct+')')
tbl.index = tbl.index.year.astype(str)
tbl.columns = [_ + ' (Err %)' for _ in tbl.columns]
tbl
#+END_SRC

#+RESULTS:
:RESULTS:
: /tmp/ipykernel_125440/2795790439.py:93: UserWarning: FixedFormatter should only be used together with FixedLocator
:   ax_D.set_xticklabels(D.index.year.unique())
: /tmp/ipykernel_125440/2795790439.py:102: RuntimeWarning: invalid value encountered in cast
:   Err_pct = (err_day_year.values/D_day_year.values*100).round().astype(int).astype(str)
#+begin_example
     CE (Err %) CW (Err %) NE (Err %) NO (Err %) NW (Err %) SE (Err %) SW (Err %)
1986     70 (9)     74 (8)     23 (8)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
1987     70 (9)     72 (8)     23 (8)     25 (8)     95 (9)    0 (NaN)    0 (NaN)
1988     70 (9)     70 (8)     22 (8)     24 (8)    0 (NaN)    0 (NaN)    0 (NaN)
1989     73 (9)     72 (8)     22 (8)     24 (8)    0 (NaN)    0 (NaN)    0 (NaN)
1990    75 (10)     69 (8)     22 (8)     23 (8)    0 (NaN)    0 (NaN)    0 (NaN)
1991    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
1992    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
1993    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    19 (10)
1994    71 (10)     69 (8)     24 (9)     25 (8)     96 (9)    0 (NaN)    0 (NaN)
1995    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
1996    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
1997    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
1998     69 (9)     74 (8)     22 (8)     23 (8)     92 (9)   130 (10)    0 (NaN)
1999     69 (9)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)    0 (NaN)
2000     69 (9)     79 (8)     23 (8)    0 (NaN)     92 (9)   131 (10)    19 (10)
2001     69 (9)     80 (8)    0 (NaN)    0 (NaN)     90 (9)   126 (10)    19 (10)
2002     72 (9)     82 (8)    0 (NaN)    0 (NaN)     92 (9)   133 (10)    19 (10)
2003     75 (9)     83 (8)    0 (NaN)    0 (NaN)     94 (9)   139 (10)    0 (NaN)
2004     78 (9)     83 (8)    0 (NaN)    0 (NaN)     98 (9)   145 (10)    0 (NaN)
2005     85 (9)     84 (8)    0 (NaN)    0 (NaN)     99 (9)   147 (10)    20 (10)
2006     84 (9)     86 (8)     25 (8)    0 (NaN)     97 (9)   139 (11)    20 (10)
2007     81 (9)     85 (8)    0 (NaN)     26 (8)     96 (9)   136 (11)    19 (10)
2008     79 (9)     87 (8)    0 (NaN)    0 (NaN)     98 (9)   140 (11)    18 (10)
2009     78 (9)     89 (8)     25 (8)    0 (NaN)    101 (9)   143 (11)    18 (10)
2010     77 (9)     89 (8)    0 (NaN)    0 (NaN)    103 (9)   143 (11)    17 (10)
2011     79 (9)     89 (8)    0 (NaN)    0 (NaN)    106 (9)   142 (11)    19 (10)
2012     79 (9)     93 (8)     26 (8)     25 (8)    105 (9)   139 (11)    19 (10)
2013     78 (9)     95 (8)     26 (8)     25 (8)    109 (9)   140 (11)    20 (10)
2014     76 (9)     94 (8)     28 (8)     26 (8)    111 (9)   138 (11)    19 (10)
2015     76 (9)     94 (8)     28 (8)     26 (8)    111 (9)   141 (11)    19 (10)
2016     73 (9)     90 (8)     29 (8)     27 (8)    113 (9)   134 (11)    18 (10)
2017     78 (9)     82 (8)     29 (8)     28 (8)    115 (9)   144 (11)    19 (10)
2018     80 (9)     79 (8)     30 (9)     29 (8)    115 (9)   142 (11)    18 (10)
2019     81 (9)     80 (8)     30 (9)     29 (9)    111 (9)   148 (11)    18 (10)
2020     86 (9)     85 (8)     30 (9)     28 (8)    110 (9)   150 (11)    19 (10)
2021     83 (9)     90 (8)     31 (9)     27 (8)    113 (9)   149 (11)    19 (10)
2022     85 (9)     84 (8)     31 (9)     27 (8)    115 (9)   146 (11)    19 (10)
2023     82 (9)     81 (8)     31 (9)     27 (8)    115 (9)   135 (11)    19 (10)
#+end_example
: <Figure size 900x700 with 1 Axes>
:END:

* Greenland outline

#+BEGIN_SRC bash
grass -c EPSG:3413 G_3413

v.import input=/home/kdm/data.me/GIS/NaturalEarth/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp output=countries
v.extract input=countries output=greenland where='name = "Greenland"'
v.out.ogr input=greenland output=greenland.gpkg

v.import input=/home/kdm/data/Zwally_2012/sectors/sectors.shp output=zwally_2012
g.region vector=zwally_2012 res=100 -ap
v.to.rast input=zwally_2012 output=z_rast use=val val=1
r.to.vect input=z_rast output=ice_edge type=area
v.out.ogr input=ice_edge output=ice_edge.gpkg
#+END_SRC

#+RESULTS:


* Bare ice area

#+BEGIN_SRC jupyter-python :exports both
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xarray as xr
import datetime

from matplotlib import rc
rc('font', size=11)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
fig.clf()
fig.set_tight_layout(True)
import matplotlib.gridspec as gridspec

ax = fig.add_subplot(111)
colors = ['purple','k', 'r', 'darkorange', 'b', 'g','lightgreen']

ds = xr.open_mfdataset('./Adrien/SICE_GrIS_bare_ice_area_*.nc')
df = ds.to_dataframe()

this_y = datetime.datetime.now().year

for i,y in enumerate(df.index.year.unique()[::-1]):
    data = df[df.index.year == y]
    data = data.resample('1D').ffill()
    data = data[(data.index.dayofyear > 130) & (data.index.dayofyear < 267)]
    ax.plot(data.index.dayofyear,
            data['bare_ice_area_km2'],
            # drawstyle='steps-post',
            color=colors[i],
            linewidth = (2 if y == this_y else 1),
            label=str(y))

ax.legend(fontsize=9, frameon=True, bbox_to_anchor=(0, 0.9), loc='upper left')

from adjust_spines import adjust_spines as adj
adj(ax, ['left','bottom'])

ax.set_ylabel('Bare ice area [km$^{2}$]')
import matplotlib.dates as mdates

label = data.index[(data.index.day == 1) | (data.index.day == 15)]
ax.set_xticks(label.dayofyear)
ax.set_xticklabels([str(_)[5:10] for _ in label])
ax.set_xticklabels(['May 15','June 1','June 15','July 1','July 15','Aug 1','Aug 15','Sep 1','Sep 15'])
plt.xticks(rotation=45)


# ax.get_yaxis().set_major_formatter(
#     mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))

ax.grid(visible=True, which='major', axis='y', alpha=0.33)
ax.grid(visible=True, which='major', axis='x', alpha=0.33)

plt.savefig('bare_ice.png', transparent=False, bbox_inches='tight', dpi=300)
plt.savefig('bare_ice.svg', transparent=False, bbox_inches='tight', dpi=300)
#+END_SRC

#+RESULTS:
[[file:./figs_tmp/1bea978be84914ff8759f383cdef4971cc9c45cc.png]]



* Melt

#+BEGIN_SRC bash
ls TM
#+END_SRC

#+RESULTS:
| cropped.tif                                                                   |
| greenland_climatological_mean_cumulative_melt_colorless_19810401-20100831.tif |
| greenland-cumulative-melt-climatology.csv                                     |
| greenland-cumulative-melt.csv                                                 |
| greenland-daily-melt-climatology.csv                                          |
| greenland-daily-melt.csv                                                      |
| greenland-daily-melt.xlsx                                                     |
| greenland_melt_anomaly_20230401_20230831.eps                                  |
| greenland_melt_anomaly_20230401_20230831.png                                  |
| greenland_melt_anomaly_20230401_20230831.svg                                  |
| greenland_melt_anomaly_20230401_20230831.tif                                  |
| greenland_melt_anomaly_20230401_20230831_tmb.png                              |
| greenland_melt_anomaly_colorless_20230401-20230831.tif                        |
| mote_arctic_report_card_request_20230401-20230831.zip                         |

#+BEGIN_SRC bash :eval no
grass -c ./G_3413/TM

g.region vector=greenland@PERMANENT res=500 -pa

r.import input=TM/greenland_melt_anomaly_colorless_20230401-20230831.tif output=melt extent=input

# d.mon wx0
# d.rast melt

eval $(g.region -upg raster=melt)

r.mask vector=greenland@PERMANENT
g.region zoom=MASK
r.mapcalc "cropped = melt"

g.region raster=cropped
r.out.gdal input=cropped output=TM/cropped.tif format=GTiff createopt="COMPRESS=DEFLATE"
#+END_SRC

** Figure
#+NAME: melt
#+BEGIN_SRC jupyter-python :exports both
import numpy as np
import pandas as pd
import geopandas as gp
import rasterio as rio
import rasterio.mask
import matplotlib
import matplotlib.pyplot as plt
from rasterio.plot import plotting_extent
import cmocean
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)

fig = plt.figure(1, figsize=(8,8)) # w,h
fig.clf()

gs = gridspec.GridSpec(2,2, width_ratios=[1,1], height_ratios=[4,1]) #w,h

ax_melt_map = plt.subplot(gs[0,1])
ax_melt_plot = plt.subplot(gs[1,1])

C_land = "#EAEAEA"
C_ocean = "#D0CFD4"

# ax_melt_map.set_facecolor(C_ocean)

if 'r_melt' not in locals():
    r_melt = rio.open('./TM/cropped.tif')
    r_melt_extent = plotting_extent(r_melt)

    r_melt = r_melt.read(1)
    r_melt[r_melt== -999] = np.nan

if 'o' not in locals():
    o = gp.read_file('greenland.gpkg')
    
o.plot(color=C_land, ax=ax_melt_map, facecolor='none', zorder=-1)

cmap = matplotlib.cm.get_cmap(cmocean.cm.balance)
im_melt = ax_melt_map.imshow(r_melt, extent=r_melt_extent,
                             cmap=cmap,
                             vmin=-40, vmax=40)

ax_melt_map.axis('off')

ax_melt_cb = inset_axes(ax_melt_map,
                        width="5%",  # width = 5% of parent_bbox width
                        height="25%",  # height : 50%
                        loc='lower right',
                        bbox_to_anchor=(-0.25, 0, 1, 1),
                        bbox_transform=ax_melt_map.transAxes,
                        borderpad=0)


cb_melt = fig.colorbar(im_melt, cax=ax_melt_cb)
cb_melt.set_label('Melt anomaly\n[days]')


df0 = pd.read_csv('TM/greenland-daily-melt.csv', parse_dates=True, index_col=0)
df1 = pd.read_csv('TM/greenland-daily-melt-climatology.csv')
df1['date'] = [pd.to_datetime('2023-01-01') + pd.to_timedelta(doy-1, unit='D') for doy in df1['doy']]
df1 = df1.set_index('date')
df = df0.merge(df1, left_index=True, right_index=True)
df[df['qc_flag'] != True] = np.nan

df = df.apply(lambda x: x/df['icesheet_area_km2_x']*100)

ax_melt_plot.plot(df['Median'], color='k', linestyle='--', drawstyle='steps-post', label='Median')
ax_melt_plot.plot(df['melting_area_km2'],
         color=np.array(cmap(185, bytes=True)[0:3])/255,
         drawstyle='steps-post',
         label='2023',
         linewidth=1.0)

ax_melt_plot.fill_between(df.index,
                 df['10'].values.flatten(),
                 df['90'].values.flatten(),
                 color='gray',
                 step='post',
                 label='Interdecile range',
                 alpha=0.25)

ax_melt_plot.fill_between(df.index,
                 df['25'].values.flatten(),
                 df['75'].values.flatten(),
                 color='k',
                 step='post',
                 label='Interquartile range',
                 alpha=0.25)

ax_melt_plot.legend(fontsize=9, frameon=False, bbox_to_anchor=(0, 1.25), loc='upper left', ncol=2)

from adjust_spines import adjust_spines as adj
adj(ax_melt_plot, ['left','bottom'])

ax_melt_plot.set_ylim(0,60)
ax_melt_plot.set_yticks([0,20,40,60])
ax_melt_plot.spines['left'].set_bounds(0,60)
ax_melt_plot.set_ylabel('Melt area\n[%]')
# ax_melt_plot.xticks(rotation=70)
# plt.setp(ax_melt_plot.xaxis.get_majorticklabels(), rotation=70)
import matplotlib.dates as mdates

ax_melt_plot.xaxis.set_major_formatter(mdates.DateFormatter('%b'))

ax_melt_plot.grid(visible=True, which='major', axis='y', alpha=0.33)

plt.savefig('melt.png', transparent=False, bbox_inches='tight', dpi=300)
plt.savefig('melt.svg', transparent=False, bbox_inches='tight', dpi=300)
#+End_src

#+RESULTS: melt
[[file:./figs_tmp/3c79ef31d75cc83757e23a9aad4c39fba5dd5453.png]]





* PROMICE In situ / Point obs

#+BEGIN_SRC jupyter-python :exports both
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib.cm as cm
import numpy as np
import pandas as pd
import geopandas as gp
import rasterio as rio
import rasterio.mask
from rasterio.plot import plotting_extent
import cmocean
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

from matplotlib import rc
rc('font', size=10)
rc('text', usetex=False)

fig = plt.figure(1, figsize=(8,8)) # w,h
fig.clf()
# fig.set_tight_layout(True)
import matplotlib.gridspec as gridspec

gs = gridspec.GridSpec(2,2, width_ratios=[1,1], height_ratios=[5,1]) #w,h

ax_map = plt.subplot(gs[0,1])

C_land = "#EAEAEA"
C_ocean = "#D0CFD4"
sub = ['THU_L','KPC_L','UPE_L','SCO_L','KAN_L','NUK_L','TAS_L','QAS_L']

if 'o' not in locals():
    o = gp.read_file('greenland.gpkg')
    
o.plot(color=C_land, ax=ax_map, facecolor='none', zorder=-1)

ice = gp.read_file('ice_edge.gpkg')
ice.boundary.plot(color='k', ax=ax_map, facecolor='None', alpha=0.25, linewidth=0.5, zorder=-1)

ax_map.axis('off')

anom = pd.read_csv('./DVA/PROMICE ablation anomalies (%) (1991-2020 ref).csv',
                  index_col=0, parse_dates=True)
unc = anom.loc['Uncertainty']
anom = anom.loc['2023']

abl = pd.read_csv('./promice_ice_ablation_2023.txt',
                  delim_whitespace=True, index_col=0)
abl = abl.loc[2023]
abl = abl[abl.index.str.contains('|'.join(sub))]
abl.index = [_.split('_')[0] for _ in abl.index]

s = gp.read_file('/home/kdm/data.me/PROMICE/stations.gpkg', index_col=0)\
    .drop(columns=['description','timestamp','begin','end','altitudeMode',
                   'tessellate','visibility','drawOrder','icon',
                   'extrude'])\
    .to_crs('EPSG:3413')

s = s[s['Name'].str.contains('|'.join(sub))]
s['Name'] = [_.split('_')[0] for _ in s['Name']]

s['x'] = s['geometry'].x
s['y'] = s['geometry'].y

s['lon'] = s.to_crs('EPSG:4326')['geometry'].x
s['lat'] = s.to_crs('EPSG:4326')['geometry'].y
s.to_csv('stations.csv')

s = s.merge(anom, left_on='Name', right_index=True)\
     .rename(columns={'2023':'anom'})

s = s.merge(abl, left_on='Name', right_index=True)\
     .rename(columns={2023:'abl'})

s = s.merge(unc, left_on='Name', right_index=True)\
     .rename(columns={'Uncertainty':'unc'})

# ax_map.scatter(s['x'], s['y'], c=s['anom'], s=s['abl']*100, cmap=mpl.cm.RdBu_r)
s['color'] = s['anom'].where(np.abs(s['anom']) > s['unc'])
sc = s.where(~np.isnan(s['color'])).dropna()

# C = sc['color']; C = (C - C.min()) / (C.max()-C.min()); C=(255*C).astype(int)
C = sc['color']; C = ((C + 100)/200 * 255).astype(int)
cmap = mpl.cm.RdBu_r
C = cmap(C)
# C = mpl.cm.RdBu_r(sc['color']/np.max(sc['color'])*255)


im = ax_map.scatter(sc['x'], sc['y'], facecolor=C, s=sc['abl']*100, edgecolor='k', alpha=1, vmin=-100, vmax=100)

sw = s.where(np.isnan(s['color'])).dropna(subset=['Name'])
ax_map.scatter(sw['x'], sw['y'], facecolor='w', s=sw['abl']*100, edgecolor='k')

# ax_map.scatter(-38.4576926,72.579521, facecolor='k')
# summit = gp.GeoDataFrame(geometry=gp.points_from_xy([-38.4576926],[72.579521])).set_crs('EPSG:4326').to_crs('EPSG:3413')
# ax_map.scatter(summit['geometry'].x,summit['geometry'].y, color='k')
# ax_map.annotate('Summit',
#                 xy=(summit['geometry'].x, summit['geometry'].y),
#                 xycoords='data',
#                 xytext=(summit['geometry'].x, summit['geometry'].y-75000),
#                 textcoords='data',
#                 fontsize=12, color='k',
#                 # fontweight='bold',
#                 ha="center", va="center")

def do_text(st, color):
    xoffset = 0 if st['Name'] != 'THU' else -150000
    t0 = ax_map.annotate(st['Name'],
                         xy=(st['x'], st['y']),
                         xycoords='data',
                         xytext=(st['x']+xoffset, st['y']),
                         textcoords='data',
                         fontsize=6, color=color, fontweight='bold',
                         ha="center", va="center")

    plussign = '+' if st["anom"] > 0 else ''
    xoffset = {'KPC':3.0E5,
              'THU':0, # 3.0E5
              'UPE':-3.2E5,
              'SCO':+3.1E5,
              'KAN':-3.2E5,
              'TAS':3.2E5,
              'NUK':-3.2E5,
              'QAS':-3E5}
    yoffset = {'KPC':0,
              'THU':-1.7E5,
              'UPE':0,
              'SCO':0,
              'KAN':0,
              'TAS':0,
              'NUK':0,
              'QAS':0}

    
    t1 = ax_map.annotate(f'{st["abl"]} m \n {plussign}{np.round(st["anom"]).astype(int)} %',
                         xy=(st['x']+xoffset[st['Name']], st['y']+yoffset[st['Name']]),
                         xycoords='data',
                         xytext=(st['x']+xoffset[st['Name']], st['y']+yoffset[st['Name']]),
                         textcoords='data',
                         ha='center', va="center",
                         bbox=dict(boxstyle="round4,pad=0.2",
                                   fc="w", ec="k", lw=2, alpha=0.25),
                         # arrowprops=dict(arrowstyle="->",
                         #                 connectionstyle="arc3"),
                         )


 # ax.text(s['x'].values, s['y'].values, s['Name'].values)
# [ax.text(_['x'].values, _['y'].values, _['Name'].values) for _ in s]
for idx in sc.index:
    st = sc.loc[idx]
    do_text(st, 'k')

for idx in sw.index:
    st = sw.loc[idx]
    do_text(st, 'k')



# REGIONS
region = gp.read_file('/home/kdm/projects/total_mass_balance/tmp/region_interior.gpkg')
region.plot(ax=ax_map, edgecolor='k', facecolor='None', alpha=1)
ax_map.text(-1E5, -1.1E6, 'NO')#, transform=ax_map.TransAxes)
ax_map.text(-2E5, -1.7E6, 'NW')#, transform=ax_map.TransAxes)
ax_map.text(3E5, -1.5E6, 'NE')#, transform=ax_map.TransAxes)
ax_map.text(-1E5, -2.1E6, 'CW')#, transform=ax_map.TransAxes)
ax_map.text(4E5, -2.1E6, 'CE')#, transform=ax_map.TransAxes)
ax_map.text(-1.6E5, -2.7E6, 'SW')#, transform=ax_map.TransAxes)
ax_map.text(1.6E5, -2.5E6, 'SE')#, transform=ax_map.TransAxes)




ax_map_cb = inset_axes(ax_map,
                       width="3%",  # width = 5% of parent_bbox width
                       height="17%",  # height : 50%
                       loc='lower right',
                       bbox_to_anchor=(-0.25, 0.05, 1, 1),
                       axes_kwargs={'yticks':[-100.,100.]},
                       bbox_transform=ax_map.transAxes,
                       borderpad=0)
cb = fig.colorbar(cm.ScalarMappable(norm=None, cmap=cmap),
                  cax=ax_map_cb,
                  label='Ablation Anomaly\n[%]')
cb.ax.set_yticks([0,0.5,1])
cb.ax.set_yticklabels([-100,0,100])
    
plt.savefig('ablation.svg', transparent=False, bbox_inches='tight', dpi=300)
plt.savefig('ablation.png', transparent=False, bbox_inches='tight', dpi=300)
     
# [['Name','anom','abl','unc']]
#+END_SRC

#+RESULTS:
[[file:./figs_tmp/ad0b31f1f428d8f120bbb83634a5167ea2c65c73.png]]


